{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/data_analytics/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "\n",
    "import params as p\n",
    "import functions as f\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import optuna\n",
    "from optuna.integration import XGBoostPruningCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, val = f.load_split_datasets(part='03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = f.split_data_X_y(train)\n",
    "X_test, y_test = f.split_data_X_y(test)\n",
    "X_val, y_val = f.split_data_X_y(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = {'X' : X_train, 'y' : y_train}\n",
    "test_data = {'X' : X_test, 'y' : y_test}\n",
    "val_data = {'X' : X_val, 'y' : y_val}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(random_state = p.RANDOM_STATE).fit(**train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse : 210.90439104107836\n",
      "mae : 128.63407599728723\n",
      "r2 : 0.8921120431393053\n"
     ]
    }
   ],
   "source": [
    "f.evaluate_model(xgb, **val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-25 14:43:14,341]\u001b[0m A new study created in memory with name: no-name-f74b5b17-ed66-4f66-9305-50d3a9d6165b\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:18,653]\u001b[0m Trial 5 finished with value: 218.29431247617296 and parameters: {'max_depth': 4, 'min_child_weight': 10, 'n_estimators': 142, 'subsample': 0.5884444564902216}. Best is trial 5 with value: 218.29431247617296.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:21,017]\u001b[0m Trial 1 finished with value: 194.29362272710657 and parameters: {'max_depth': 7, 'min_child_weight': 4, 'n_estimators': 111, 'subsample': 0.3972683130629646}. Best is trial 1 with value: 194.29362272710657.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:21,229]\u001b[0m Trial 0 finished with value: 215.6383744461178 and parameters: {'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 182, 'subsample': 0.13487288342032044}. Best is trial 1 with value: 194.29362272710657.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:23,133]\u001b[0m Trial 2 finished with value: 215.44059756812203 and parameters: {'max_depth': 4, 'min_child_weight': 5, 'n_estimators': 799, 'subsample': 0.24427023712600793}. Best is trial 1 with value: 194.29362272710657.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:25,674]\u001b[0m Trial 9 finished with value: 193.74690652920444 and parameters: {'max_depth': 7, 'min_child_weight': 4, 'n_estimators': 74, 'subsample': 0.8621854987607743}. Best is trial 9 with value: 193.74690652920444.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:25,676]\u001b[0m Trial 10 pruned. Trial was pruned at iteration 152.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:25,729]\u001b[0m Trial 13 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:25,773]\u001b[0m Trial 14 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:25,811]\u001b[0m Trial 15 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:25,832]\u001b[0m Trial 12 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:25,854]\u001b[0m Trial 16 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:27,023]\u001b[0m Trial 3 finished with value: 214.7020164813826 and parameters: {'max_depth': 3, 'min_child_weight': 10, 'n_estimators': 549, 'subsample': 0.6970561006784599}. Best is trial 9 with value: 193.74690652920444.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:27,028]\u001b[0m Trial 4 pruned. Trial was pruned at iteration 548.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:27,033]\u001b[0m Trial 8 pruned. Trial was pruned at iteration 468.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:29,802]\u001b[0m Trial 6 finished with value: 193.48118417154583 and parameters: {'max_depth': 7, 'min_child_weight': 7, 'n_estimators': 678, 'subsample': 0.6402723927960456}. Best is trial 6 with value: 193.48118417154583.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:37,946]\u001b[0m Trial 18 finished with value: 195.36674873923445 and parameters: {'max_depth': 7, 'min_child_weight': 7, 'n_estimators': 382, 'subsample': 0.8714240008954548}. Best is trial 6 with value: 193.48118417154583.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:38,907]\u001b[0m Trial 20 finished with value: 193.94472471719587 and parameters: {'max_depth': 7, 'min_child_weight': 6, 'n_estimators': 285, 'subsample': 0.8622682853505481}. Best is trial 6 with value: 193.48118417154583.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:38,929]\u001b[0m Trial 23 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:39,014]\u001b[0m Trial 24 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:39,073]\u001b[0m Trial 25 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:39,149]\u001b[0m Trial 26 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:39,150]\u001b[0m Trial 27 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:39,268]\u001b[0m Trial 28 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:39,364]\u001b[0m Trial 30 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:39,668]\u001b[0m Trial 29 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:39,752]\u001b[0m Trial 31 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:39,762]\u001b[0m Trial 32 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:39,860]\u001b[0m Trial 34 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:39,867]\u001b[0m Trial 33 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:39,954]\u001b[0m Trial 36 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:39,969]\u001b[0m Trial 35 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:40,086]\u001b[0m Trial 37 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:40,154]\u001b[0m Trial 38 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:40,189]\u001b[0m Trial 39 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:40,350]\u001b[0m Trial 41 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:42,495]\u001b[0m Trial 21 finished with value: 193.45776539603358 and parameters: {'max_depth': 7, 'min_child_weight': 6, 'n_estimators': 367, 'subsample': 0.8872782508182103}. Best is trial 21 with value: 193.45776539603358.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:42,591]\u001b[0m Trial 43 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:42,685]\u001b[0m Trial 44 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:45,906]\u001b[0m Trial 45 pruned. Trial was pruned at iteration 47.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:45,990]\u001b[0m Trial 46 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:46,066]\u001b[0m Trial 47 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:46,486]\u001b[0m Trial 19 finished with value: 194.7424836962527 and parameters: {'max_depth': 7, 'min_child_weight': 7, 'n_estimators': 349, 'subsample': 0.952503695434731}. Best is trial 21 with value: 193.45776539603358.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:46,659]\u001b[0m Trial 49 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:46,894]\u001b[0m Trial 48 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:46,988]\u001b[0m Trial 51 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:47,087]\u001b[0m Trial 52 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:47,368]\u001b[0m Trial 53 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:47,461]\u001b[0m Trial 54 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:47,564]\u001b[0m Trial 55 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:47,633]\u001b[0m Trial 56 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:47,682]\u001b[0m Trial 22 finished with value: 192.52211517902003 and parameters: {'max_depth': 7, 'min_child_weight': 7, 'n_estimators': 385, 'subsample': 0.8511873168628509}. Best is trial 22 with value: 192.52211517902003.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:47,738]\u001b[0m Trial 57 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:47,794]\u001b[0m Trial 58 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:47,828]\u001b[0m Trial 59 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:47,884]\u001b[0m Trial 61 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:47,948]\u001b[0m Trial 60 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:48,094]\u001b[0m Trial 63 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:48,159]\u001b[0m Trial 62 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:48,168]\u001b[0m Trial 64 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:48,262]\u001b[0m Trial 65 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:48,279]\u001b[0m Trial 66 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:48,318]\u001b[0m Trial 7 finished with value: 190.6220553122903 and parameters: {'max_depth': 6, 'min_child_weight': 3, 'n_estimators': 741, 'subsample': 0.4923650226380817}. Best is trial 7 with value: 190.6220553122903.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:48,390]\u001b[0m Trial 67 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:48,412]\u001b[0m Trial 68 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:48,552]\u001b[0m Trial 71 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:48,560]\u001b[0m Trial 42 pruned. Trial was pruned at iteration 131.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:48,673]\u001b[0m Trial 72 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:48,674]\u001b[0m Trial 73 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:48,695]\u001b[0m Trial 70 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:48,790]\u001b[0m Trial 75 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:48,791]\u001b[0m Trial 74 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:48,792]\u001b[0m Trial 76 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:48,972]\u001b[0m Trial 79 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:48,972]\u001b[0m Trial 78 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:49,084]\u001b[0m Trial 81 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:49,149]\u001b[0m Trial 80 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:49,195]\u001b[0m Trial 82 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:49,262]\u001b[0m Trial 84 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:49,335]\u001b[0m Trial 77 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:49,420]\u001b[0m Trial 85 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:49,510]\u001b[0m Trial 83 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:51,612]\u001b[0m Trial 17 finished with value: 193.4784860125095 and parameters: {'max_depth': 7, 'min_child_weight': 7, 'n_estimators': 419, 'subsample': 0.9399662476672527}. Best is trial 7 with value: 190.6220553122903.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:51,776]\u001b[0m Trial 89 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:52,205]\u001b[0m Trial 90 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:52,608]\u001b[0m Trial 91 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:53,025]\u001b[0m Trial 92 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:53,114]\u001b[0m Trial 93 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:53,249]\u001b[0m Trial 94 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:53,531]\u001b[0m Trial 95 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:53,576]\u001b[0m Trial 96 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:53,631]\u001b[0m Trial 97 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:55,244]\u001b[0m Trial 88 pruned. Trial was pruned at iteration 92.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:55,505]\u001b[0m Trial 98 pruned. Trial was pruned at iteration 27.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:55,592]\u001b[0m Trial 100 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:55,681]\u001b[0m Trial 101 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:55,774]\u001b[0m Trial 102 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:55,870]\u001b[0m Trial 103 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:57,120]\u001b[0m Trial 99 pruned. Trial was pruned at iteration 27.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:57,188]\u001b[0m Trial 105 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:57,277]\u001b[0m Trial 106 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:57,376]\u001b[0m Trial 107 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:57,427]\u001b[0m Trial 108 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:57,484]\u001b[0m Trial 109 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:57,556]\u001b[0m Trial 110 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:57,612]\u001b[0m Trial 111 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:57,683]\u001b[0m Trial 112 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:57,776]\u001b[0m Trial 40 finished with value: 191.84056965017965 and parameters: {'max_depth': 7, 'min_child_weight': 5, 'n_estimators': 838, 'subsample': 0.4435844530678701}. Best is trial 7 with value: 190.6220553122903.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:57,777]\u001b[0m Trial 113 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:57,951]\u001b[0m Trial 115 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:58,001]\u001b[0m Trial 87 finished with value: 190.89800732057594 and parameters: {'max_depth': 7, 'min_child_weight': 6, 'n_estimators': 139, 'subsample': 0.572728359284547}. Best is trial 7 with value: 190.6220553122903.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:58,094]\u001b[0m Trial 104 pruned. Trial was pruned at iteration 30.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:58,183]\u001b[0m Trial 118 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:58,257]\u001b[0m Trial 116 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:58,281]\u001b[0m Trial 117 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:58,439]\u001b[0m Trial 120 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:58,439]\u001b[0m Trial 121 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:58,529]\u001b[0m Trial 119 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:58,555]\u001b[0m Trial 123 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:58,637]\u001b[0m Trial 124 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:58,643]\u001b[0m Trial 125 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:58,741]\u001b[0m Trial 122 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:58,780]\u001b[0m Trial 126 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:58,809]\u001b[0m Trial 127 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:58,897]\u001b[0m Trial 128 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:58,904]\u001b[0m Trial 130 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:59,012]\u001b[0m Trial 131 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:59,167]\u001b[0m Trial 133 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:59,238]\u001b[0m Trial 134 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:59,517]\u001b[0m Trial 135 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:59,616]\u001b[0m Trial 136 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:59,643]\u001b[0m Trial 132 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:59,711]\u001b[0m Trial 138 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:59,718]\u001b[0m Trial 137 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:59,795]\u001b[0m Trial 139 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:59,795]\u001b[0m Trial 140 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:59,866]\u001b[0m Trial 142 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:59,876]\u001b[0m Trial 141 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:59,916]\u001b[0m Trial 50 finished with value: 191.39151499383053 and parameters: {'max_depth': 7, 'min_child_weight': 4, 'n_estimators': 270, 'subsample': 0.613781459000802}. Best is trial 7 with value: 190.6220553122903.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:43:59,967]\u001b[0m Trial 143 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:00,024]\u001b[0m Trial 144 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:00,076]\u001b[0m Trial 146 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:00,123]\u001b[0m Trial 147 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:00,334]\u001b[0m Trial 145 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:00,809]\u001b[0m Trial 150 pruned. Trial was pruned at iteration 6.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:00,901]\u001b[0m Trial 151 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:01,167]\u001b[0m Trial 152 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:01,253]\u001b[0m Trial 153 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:01,408]\u001b[0m Trial 154 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:01,667]\u001b[0m Trial 155 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:01,766]\u001b[0m Trial 156 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:01,838]\u001b[0m Trial 157 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:01,912]\u001b[0m Trial 158 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:01,993]\u001b[0m Trial 159 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:02,062]\u001b[0m Trial 160 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:02,127]\u001b[0m Trial 161 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:02,234]\u001b[0m Trial 162 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:02,425]\u001b[0m Trial 114 pruned. Trial was pruned at iteration 75.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:02,850]\u001b[0m Trial 164 pruned. Trial was pruned at iteration 5.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:02,944]\u001b[0m Trial 165 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:03,566]\u001b[0m Trial 129 finished with value: 198.4860570659508 and parameters: {'max_depth': 7, 'min_child_weight': 4, 'n_estimators': 74, 'subsample': 0.6820639209351833}. Best is trial 7 with value: 190.6220553122903.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:03,817]\u001b[0m Trial 167 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:04,107]\u001b[0m Trial 168 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:04,555]\u001b[0m Trial 148 pruned. Trial was pruned at iteration 68.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:04,767]\u001b[0m Trial 170 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:05,025]\u001b[0m Trial 166 pruned. Trial was pruned at iteration 30.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:05,075]\u001b[0m Trial 86 finished with value: 188.83892187695866 and parameters: {'max_depth': 7, 'min_child_weight': 4, 'n_estimators': 253, 'subsample': 0.6312994793450162}. Best is trial 86 with value: 188.83892187695866.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:05,357]\u001b[0m Trial 173 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:05,640]\u001b[0m Trial 174 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:05,995]\u001b[0m Trial 175 pruned. Trial was pruned at iteration 4.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:07,468]\u001b[0m Trial 11 finished with value: 188.07696997148358 and parameters: {'max_depth': 6, 'min_child_weight': 2, 'n_estimators': 864, 'subsample': 0.625939560573208}. Best is trial 11 with value: 188.07696997148358.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:10,407]\u001b[0m Trial 169 finished with value: 193.94703190921362 and parameters: {'max_depth': 7, 'min_child_weight': 4, 'n_estimators': 100, 'subsample': 0.6958166061135351}. Best is trial 11 with value: 188.07696997148358.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:11,213]\u001b[0m Trial 172 finished with value: 191.58544492349125 and parameters: {'max_depth': 7, 'min_child_weight': 4, 'n_estimators': 97, 'subsample': 0.8492516270248673}. Best is trial 11 with value: 188.07696997148358.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:11,432]\u001b[0m Trial 178 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:11,730]\u001b[0m Trial 180 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:11,844]\u001b[0m Trial 181 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:11,947]\u001b[0m Trial 182 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:12,065]\u001b[0m Trial 183 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:12,164]\u001b[0m Trial 184 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:13,424]\u001b[0m Trial 163 finished with value: 190.74466050575464 and parameters: {'max_depth': 7, 'min_child_weight': 7, 'n_estimators': 360, 'subsample': 0.6889863614769325}. Best is trial 11 with value: 188.07696997148358.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:13,530]\u001b[0m Trial 186 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:13,695]\u001b[0m Trial 187 pruned. Trial was pruned at iteration 1.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:13,809]\u001b[0m Trial 188 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:14,096]\u001b[0m Trial 185 pruned. Trial was pruned at iteration 26.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:15,896]\u001b[0m Trial 189 pruned. Trial was pruned at iteration 30.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:15,993]\u001b[0m Trial 191 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:16,092]\u001b[0m Trial 192 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:16,390]\u001b[0m Trial 193 pruned. Trial was pruned at iteration 3.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:16,491]\u001b[0m Trial 194 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:16,599]\u001b[0m Trial 195 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:16,692]\u001b[0m Trial 196 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:16,895]\u001b[0m Trial 197 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:17,075]\u001b[0m Trial 149 finished with value: 186.2543435956945 and parameters: {'max_depth': 7, 'min_child_weight': 4, 'n_estimators': 544, 'subsample': 0.5780149142582756}. Best is trial 149 with value: 186.2543435956945.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:17,120]\u001b[0m Trial 198 pruned. Trial was pruned at iteration 2.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:17,179]\u001b[0m Trial 199 pruned. Trial was pruned at iteration 0.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:18,036]\u001b[0m Trial 179 finished with value: 190.8459628775762 and parameters: {'max_depth': 7, 'min_child_weight': 4, 'n_estimators': 111, 'subsample': 0.8535788534712819}. Best is trial 149 with value: 186.2543435956945.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:18,566]\u001b[0m Trial 176 finished with value: 183.74318957554797 and parameters: {'max_depth': 7, 'min_child_weight': 4, 'n_estimators': 400, 'subsample': 0.8488153719247543}. Best is trial 176 with value: 183.74318957554797.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:21,236]\u001b[0m Trial 69 finished with value: 188.56370031098322 and parameters: {'max_depth': 7, 'min_child_weight': 2, 'n_estimators': 816, 'subsample': 0.43991104651772406}. Best is trial 176 with value: 183.74318957554797.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:22,152]\u001b[0m Trial 171 finished with value: 188.22175607071537 and parameters: {'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 378, 'subsample': 0.8603730054757919}. Best is trial 176 with value: 183.74318957554797.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:23,015]\u001b[0m Trial 190 finished with value: 188.2394788316923 and parameters: {'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 366, 'subsample': 0.7196744390402893}. Best is trial 176 with value: 183.74318957554797.\u001b[0m\n",
      "\u001b[32m[I 2022-03-25 14:44:23,194]\u001b[0m Trial 177 finished with value: 190.7023053906035 and parameters: {'max_depth': 7, 'min_child_weight': 2, 'n_estimators': 397, 'subsample': 0.6720313732343445}. Best is trial 176 with value: 183.74318957554797.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "base_params = {\n",
    "    'learning_rate' : 0.1,\n",
    "    'verbosity' : 0,\n",
    "    'n_jobs' : -1,\n",
    "    'random_state' : p.RANDOM_STATE,\n",
    "    }\n",
    "\n",
    "def objective(trial, X_train = X_train, y_train = y_train, X_test = X_test, y_test = y_test, base_params = base_params):\n",
    "\n",
    "    obj_params = {\n",
    "        'max_depth' : trial.suggest_int('max_depth', 2, 7),\n",
    "        'min_child_weight' : trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'n_estimators' : trial.suggest_int('n_estimators', 50, 1000),\n",
    "        'subsample' : trial.suggest_float('subsample', 0.1, 1),\n",
    "\n",
    "        **base_params\n",
    "    }\n",
    "\n",
    "    pruning_callback = XGBoostPruningCallback(trial, observation_key= 'validation_1-rmse')\n",
    "\n",
    "    xgb_obj = XGBRegressor(**obj_params)\n",
    "    xgb_obj.fit(\n",
    "        **train_data,\n",
    "        eval_metric = 'rmse',\n",
    "        eval_set = [(X_train, y_train), (X_test, y_test)],\n",
    "        early_stopping_rounds = obj_params['n_estimators']*0.1,\n",
    "        verbose = 0,\n",
    "        callbacks = [pruning_callback]\n",
    "        )\n",
    "\n",
    "    y_pred = xgb_obj.predict(X_test)\n",
    "\n",
    "    rmse = (mean_squared_error(y_true = y_test, y_pred=y_pred))**0.5\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials = 200, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 7,\n",
       " 'min_child_weight': 4,\n",
       " 'n_estimators': 400,\n",
       " 'subsample': 0.8488153719247543,\n",
       " 'learning_rate': 0.1,\n",
       " 'verbosity': 0,\n",
       " 'n_jobs': -1,\n",
       " 'random_state': 73}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_params = {**study.best_params, **base_params}\n",
    "tuned_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Final XGB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n",
       "             max_depth=7, min_child_weight=4, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=400, n_jobs=-1,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=73,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "             subsample=0.8488153719247543, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_tuned = XGBRegressor(**tuned_params)\n",
    "xgb_tuned.fit(\n",
    "    **train_data,\n",
    "    eval_metric = 'rmse',\n",
    "    eval_set = [(X_train, y_train), (X_test, y_test)],\n",
    "    early_stopping_rounds = tuned_params['n_estimators'] * 0.1,\n",
    "    verbose = 0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse : 198.67011629703538\n",
      "mae : 119.62577776174032\n",
      "r2 : 0.9042658651421513\n"
     ]
    }
   ],
   "source": [
    "f.evaluate_model(xgb_tuned, **val_data)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d0be0daef6eafac08144bde7256d0240e3dc154c04f6176bdf38ffbf1040ae"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 ('itai-dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
