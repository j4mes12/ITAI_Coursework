{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "---\n",
    "Here we make the adjustments required so the data can be used in a model. We:\n",
    "- Extract features from date.\n",
    "- Turned Yes/No features into binary.\n",
    "- Create dummy variables for categorical features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import calendar\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import functions as f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, val = f.load_split_datasets(part='02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5256, 14), (1752, 14), (1752, 14))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape, val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with other categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `holiday`: map to a binary feature\n",
    "- `functioning_day`: map to a binary feature\n",
    "- `seasons`: Create dummy columns for each season. Remove one season for linear independence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn `holiday` and `functioning_day` into a binary feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cols_to_binary(df: pd.DataFrame):\n",
    "\n",
    "    df.loc[:, 'bin_holiday'] = np.where(df.loc[:, 'holiday'] == 'Holiday', 1, 0)\n",
    "    df.loc[:, 'bin_functioning_day'] = np.where(df.loc[:, 'functioning_day'] == 'Yes', 1, 0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Features from Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date_features(df: pd.DataFrame):\n",
    "\n",
    "    df.loc[:, 'weekday'] = [calendar.day_name[day] for day in df.loc[:, 'date'].dt.weekday]\n",
    "    df.loc[:, 'month'] = [calendar.month_name[month] for month in df.loc[:, 'date'].dt.month]\n",
    "    df.loc[:, 'hour'] = df.loc[:, 'hour'].astype(object)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop extra features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_extra_features(df: pd.DataFrame):\n",
    "\n",
    "    df.drop(columns = ['date', 'dew_point_temperature', 'functioning_day', 'holiday'], inplace= True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dummy features for `seasons`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummy_features(df: pd.DataFrame):\n",
    "\n",
    "    # Drop to maintain linear independence\n",
    "    df = pd.get_dummies(df, drop_first = True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"make_cols_binary\", FunctionTransformer(cols_to_binary)),\n",
    "        (\"extract_date_features\", FunctionTransformer(extract_date_features)),\n",
    "        (\"drop_extra_features\", FunctionTransformer(drop_extra_features)),\n",
    "        (\"create_dummy_features\", FunctionTransformer(create_dummy_features)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pipeline.transform(train)\n",
    "val = pipeline.transform(val)\n",
    "test = pipeline.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rented_bike_count', 'temperature', 'humidity', 'wind_speed',\n",
       "       'visibility', 'solar_radiation', 'rainfall', 'snowfall', 'bin_holiday',\n",
       "       'bin_functioning_day', 'hour_1', 'hour_2', 'hour_3', 'hour_4', 'hour_5',\n",
       "       'hour_6', 'hour_7', 'hour_8', 'hour_9', 'hour_10', 'hour_11', 'hour_12',\n",
       "       'hour_13', 'hour_14', 'hour_15', 'hour_16', 'hour_17', 'hour_18',\n",
       "       'hour_19', 'hour_20', 'hour_21', 'hour_22', 'hour_23', 'seasons_Spring',\n",
       "       'seasons_Summer', 'seasons_Winter', 'weekday_Monday',\n",
       "       'weekday_Saturday', 'weekday_Sunday', 'weekday_Thursday',\n",
       "       'weekday_Tuesday', 'weekday_Wednesday', 'month_August',\n",
       "       'month_December', 'month_February', 'month_January', 'month_July',\n",
       "       'month_June', 'month_March', 'month_May', 'month_November',\n",
       "       'month_October', 'month_September'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'train' : train,\n",
    "    'val' : val,\n",
    "    'test' : test,}\n",
    "\n",
    "f.save_split_datasets(datasets=datasets, part='03')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d186370726e06e53ef63bbbfb41b59cb3f441907eefa936ab63b28aa19e1fd33"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 ('SDPA-dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
